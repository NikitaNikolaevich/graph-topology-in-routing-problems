{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_graph(id, simplify=True):\n",
    "    gdf = ox.geocode_to_gdf(id, by_osmid=True)\n",
    "    polygon_boundary = gdf.unary_union\n",
    "    graph = ox.graph_from_polygon(polygon_boundary,\n",
    "                                  network_type='drive',\n",
    "                                  simplify=simplify)\n",
    "    G = nx.Graph(graph)\n",
    "    H = nx.Graph()\n",
    "    # Добавляем рёбра в новый граф, копируя только веса\n",
    "    for u, d in G.nodes(data=True):\n",
    "        H.add_node(u, x=d['x'], y=d['y'])\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        H.add_edge(u, v, length=d['length'])\n",
    "\n",
    "    \n",
    "    # Создание папки, если она не существует\n",
    "    directory = \"data\\graphs\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Запись графа в файл GraphML\n",
    "    file_path = os.path.join(directory, f\"graph_{id}.graphml\")\n",
    "    nx.write_graphml(H, file_path)\n",
    "    \n",
    "    print(f\"Граф с id {id} был сохранён в {file_path}\")\n",
    "    H.graph['id'] = id\n",
    "    return H\n",
    "\n",
    "def percent(l, p=0.1, max_points=10):\n",
    "    res = int(len(l) * p) if len(l) * p >= 1 else 1\n",
    "    if res > max_points:\n",
    "        res = 10\n",
    "    return res\n",
    "\n",
    "def find_points_for_experiment(G_cl, clusters, min_length=5, p=0.1, max_points=2):\n",
    "    # словарь хранит в себе {id_кластер: {other_кластер: расстояние до него}}\n",
    "    d = dict(nx.all_pairs_dijkstra_path_length(G_cl))\n",
    "    df = pd.DataFrame(d)\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    df = df.sort_index()\n",
    "    graph_path_length = df.values\n",
    "    res = []\n",
    "\n",
    "    for com_1 in range(len(graph_path_length)):\n",
    "        for com_2 in range(com_1 + 1, len(graph_path_length)):\n",
    "            if graph_path_length[com_1][com_2] >= min_length:\n",
    "                 list_1 = random.sample(clusters[com_1],\n",
    "                                        k=percent(clusters[com_1], p, max_points))\n",
    "                 list_2 = random.sample(clusters[com_2],\n",
    "                                        k=percent(clusters[com_2], p, max_points))\n",
    "                 all_lists = itertools.product(list_1, list_2)\n",
    "\n",
    "                 res.extend(list(all_lists))\n",
    "    return res\n",
    "\n",
    "def create_G_centroid(H):\n",
    "  # Запись данных - {кластер: [ids точек]}\n",
    "  clusters = {}\n",
    "  for node, data in H.nodes(data=True):\n",
    "      cluster = data['cluster']\n",
    "      if cluster not in clusters:\n",
    "          clusters[cluster] = []\n",
    "      clusters[cluster].append(node)\n",
    "\n",
    "  # Определение соседей для каждого кластера\n",
    "  # {id кластера: [ids кластеров соседей]}\n",
    "  cluster_transitions = {}\n",
    "  for cluster, nodes in clusters.items():\n",
    "      neighboring_clusters = set()\n",
    "      for node in nodes:\n",
    "          for neighbor in H.neighbors(node):\n",
    "              neighbor_cluster = H.nodes[neighbor]['cluster']\n",
    "              if neighbor_cluster != cluster:\n",
    "                  neighboring_clusters.add(neighbor_cluster)\n",
    "      cluster_transitions[cluster] = list(neighboring_clusters)\n",
    "\n",
    "  # Поиск центроид каждого кластера\n",
    "  dict_centroid = {}\n",
    "  for i in range(len(clusters)):\n",
    "    nodes_ = [node for node, data in H.nodes(data=True) if data.get('cluster') == i]\n",
    "    s = H.subgraph(nodes_)\n",
    "    closeness_centrality = nx.closeness_centrality(s)\n",
    "    centroid = max(closeness_centrality, key=closeness_centrality.get)\n",
    "    dict_centroid[i] = centroid\n",
    "\n",
    "  # Создаем граф из словаря\n",
    "  G = nx.Graph()\n",
    "  for node, neighbors in cluster_transitions.items():\n",
    "      for neighbor in neighbors:\n",
    "        nodes_ = [n for n, data in H.nodes(data=True) if data.get('cluster') in (node, neighbor)]\n",
    "        s = H.subgraph(nodes_)\n",
    "        length, path = nx.single_source_dijkstra(H,\n",
    "                                                  dict_centroid[node],\n",
    "                                                  dict_centroid[neighbor],\n",
    "                                                  weight='length')\n",
    "        G.add_edge(node, neighbor, weight=length)\n",
    "  return G, clusters\n",
    "\n",
    "def louvain_clusters(H, seed=42, weight='length', resolution=1):\n",
    "    communities = nx.community.louvain_communities(H, seed=seed,\n",
    "                                                weight=weight,\n",
    "                                                resolution=resolution)\n",
    "    for i, ids in enumerate(communities):\n",
    "        for j in ids:\n",
    "            H.nodes[j]['cluster'] = i\n",
    "    return H, communities\n",
    "\n",
    "def create_points_for_test(H, min_distance=10):\n",
    "    H, _ = louvain_clusters(H, resolution=1, weight='length') # \n",
    "    G_centroid, clusters = create_G_centroid(H)\n",
    "    random.seed(42)\n",
    "    res = find_points_for_experiment(G_centroid, clusters, min_distance)\n",
    "    return res\n",
    "\n",
    "def formula_centroid(v0, e0, e1, k):\n",
    "    return e1 * math.log(k*v0) + v0 + (e0/math.sqrt(k*v0) * (math.log(math.sqrt(v0/k))))\n",
    "\n",
    "def formula_louven(H):\n",
    "    m = len(H.nodes())\n",
    "    n = len(H.edges())\n",
    "    return (n*math.log(n) + m*math.log(n))\n",
    "\n",
    "def search_resolutions(H, resolution=0.001, weight='length', k_max=0.7):\n",
    "    resolutions = []\n",
    "    k = 0\n",
    "    ks = []\n",
    "    v1 = []\n",
    "    e1  =[]\n",
    "\n",
    "    while k < k_max:\n",
    "      H, communities = louvain_clusters(H, resolution=resolution, weight=weight)\n",
    "      k = len(communities)/len(H.nodes)\n",
    "    #   print(f'a = {len(communities)/len(H.nodes):>6.9f},\\tresolution = {resolution:>10.3f}')\n",
    "      if k < 0.008:\n",
    "        resolution *= 3\n",
    "        continue\n",
    "      else:\n",
    "        G_centroid, _ = create_G_centroid(H)\n",
    "        if len(G_centroid.nodes()) > 0 and len(G_centroid.edges()) > 0:\n",
    "          v1.append(len(G_centroid.nodes()))\n",
    "          e1.append(len(G_centroid.edges()))\n",
    "          resolutions.append(resolution)\n",
    "          ks.append(k)\n",
    "          resolution *= 3\n",
    "\n",
    "\n",
    "    return resolutions, ks, v1, e1\n",
    "\n",
    "def visualisation(H, v1, e1, show=False):\n",
    "    v0 = len(H.nodes())\n",
    "    e0 = len(H.edges())\n",
    "\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "\n",
    "    for i in range(len(v1)):\n",
    "        vi = v1[i]\n",
    "        ei = e1[i]\n",
    "        k = vi/v0\n",
    "        y = formula_centroid(v0, e0, ei, k)  # Убедитесь, что функция formula_centroid определена\n",
    "        x_values.append(round(k, 3))\n",
    "        y_values.append(y)\n",
    "\n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.plot(x_values, y_values, 'ro-', label='Асимптотическое время')  # Добавляем метку для красных точек\n",
    "    plt.xlabel('k, отношение кластеров к узлам графа')\n",
    "    plt.ylabel('Эволюция асимптотического времени')\n",
    "    plt.title('Асимптотическое время работы')\n",
    "\n",
    "    # Вызываем функцию formula_louven и добавляем горизонтальную линию\n",
    "    louven_value = formula_louven(H)\n",
    "    plt.axhline(y=louven_value, color='g', linestyle='--', label='Алгоритм Лувена')  # Добавляем метку для горизонтальной линии\n",
    "    plt.legend()  # Отображаем легенду на графике\n",
    "\n",
    "    # Создание папки, если она не существует\n",
    "    directory = \"data\\img\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Запись графа в файл GraphML\n",
    "    file_path = os.path.join(directory, f\"асимптота_{H.graph['id']}.png\")\n",
    "    plt.savefig(file_path, dpi=120)\n",
    "    \n",
    "    print(f\"График асимптоты был сохранён в {file_path}\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "def test(H: nx.Graph, resolutions: list, k: int=100, min_distance: int=10, weight:str='length'):\n",
    "\n",
    "    res = create_points_for_test(H, min_distance=min_distance)\n",
    "\n",
    "    output = {\n",
    "        'error': [],\n",
    "        'time_centr': [],\n",
    "        'times': [],\n",
    "        'ks': [],\n",
    "    }\n",
    "\n",
    "    mistakes = {\n",
    "      \n",
    "    }\n",
    "\n",
    "    try:\n",
    "        part = random.sample(res, k=k)\n",
    "    except ValueError:\n",
    "        part = res  # Если k больше размера популяции или отрицательно, используем весь список\n",
    "\n",
    "    start = time.time()\n",
    "    all_length = []\n",
    "    print('\\nТестирование на начальном графе:')\n",
    "    for i in tqdm(part):\n",
    "        length, path1 = nx.single_source_dijkstra(H, i[0], i[1], weight=weight)\n",
    "        all_length.append(length)\n",
    "    end = time.time()\n",
    "    output['dijkstra_time'] = end - start\n",
    "\n",
    "    v1 = []\n",
    "    e1  =[]\n",
    "\n",
    "    print('\\nТестирование на центроидах:')\n",
    "    for resolution in resolutions:\n",
    "        H, communities = louvain_clusters(H, resolution=resolution, weight=weight)\n",
    "        k = len(communities)/len(H.nodes)\n",
    "        output['ks'].append(round(k, 3))\n",
    "\n",
    "        start_centr = time.time()\n",
    "        G_centroid, clusters = create_G_centroid(H)\n",
    "        end_centr = time.time() - start_centr\n",
    "        output['time_centr'].append(end_centr)\n",
    "        v1.append(len(G_centroid.nodes()))\n",
    "        e1.append(len(G_centroid.edges()))\n",
    "\n",
    "        all_l_c = []\n",
    "        start = time.time()\n",
    "        for i in tqdm(part):\n",
    "\n",
    "            cluster_1 = H.nodes(data=True)[i[0]]['cluster']\n",
    "            cluster_2 = H.nodes(data=True)[i[1]]['cluster']\n",
    "            leng_G = nx.dijkstra_path(G_centroid, cluster_1, cluster_2)\n",
    "            nodes = []\n",
    "            for g_name in leng_G:\n",
    "                nodes.extend(clusters[g_name])\n",
    "            Hs = H.subgraph(nodes)\n",
    "            length,path2 = nx.single_source_dijkstra(Hs, i[0], i[1], weight='length')\n",
    "\n",
    "            all_l_c.append(length)\n",
    "\n",
    "        result = time.time() - start\n",
    "        output['times'].append(result)\n",
    "        mis = (np.array(all_l_c).sum() - np.array(all_length).sum()) / np.array(all_length).sum() * 100\n",
    "        mis_box_plot = (np.array(all_l_c) - np.array(all_length)) / np.array(all_length) * 100\n",
    "        mistakes[round(k, 3)] = mis_box_plot\n",
    "        output['error'].append(mis)\n",
    "        \n",
    "    output = pd.DataFrame(output)\n",
    "    mistakes = pd.DataFrame(mistakes)\n",
    "    # Создание папки, если она не существует\n",
    "    directory = \"data\\csv\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Запись CSV\n",
    "    file_path_output = os.path.join(directory, f\"output_{H.graph['id']}.csv\")\n",
    "    file_path_mistakes = os.path.join(directory, f\"mistakes_{H.graph['id']}.csv\")\n",
    "\n",
    "    output.to_csv(file_path_output, index=False)\n",
    "    print(f\"output_{H.graph['id']}.csv был сохранён в {file_path_output}\")\n",
    "    \n",
    "    mistakes.to_csv(file_path_mistakes, index=False)\n",
    "    print(f\"mistakes_{H.graph['id']}.csv был сохранён в {file_path_mistakes}\")\n",
    "\n",
    "    return output, mistakes\n",
    "\n",
    "def box_visualisation(H, output, mistakes, y=10, show=False):\n",
    "    plt.figure(figsize=(16,9))\n",
    "    ax1 = mistakes.boxplot(showfliers=False, grid=False)\n",
    "    plt.xticks(range(1, len(mistakes.columns)+1), mistakes.columns)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(range(1, len(output['times'])+1), output['times'], 'ro-')\n",
    "    \n",
    "    # Добавляем горизонтальную линию на уровне y\n",
    "    ax1.axhline(y=y, color='g', linestyle='--')\n",
    "    \n",
    "    # Устанавливаем подписи для осей\n",
    "    ax1.set_ylabel('Ошибки, %', color='b')\n",
    "    ax2.set_ylabel('Время, сек', color='r')\n",
    "    # Устанавливаем цвета для осей\n",
    "    for tl in ax1.get_yticklabels():\n",
    "        tl.set_color('b')\n",
    "    for tl in ax2.get_yticklabels():\n",
    "        tl.set_color('r')\n",
    "    ax1.set_xlabel('k, отношение кластеров к узлам графа')\n",
    "    plt.title('Поиск оптимального отношения кластеров к кол-ву узлов в графе')\n",
    "    \n",
    "    # Создание папки, если она не существует\n",
    "    directory = \"data\\img\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Запись PNG\n",
    "    file_path = os.path.join(directory, f\"boxplot_{H.graph['id']}.png\")\n",
    "    plt.savefig(file_path, dpi=120)\n",
    "    \n",
    "    print(f\"График boxplot был сохранён в {file_path}\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "def box_visualisation(H, output, mistakes, y=10, show=False):\n",
    "    plt.figure(figsize=(16,9))\n",
    "    ax1 = mistakes.boxplot(showfliers=False, grid=False)\n",
    "    plt.xticks(range(1, len(mistakes.columns)+1), mistakes.columns)\n",
    "    ax2 = ax1.twinx()\n",
    "    # Добавляем метку для линейного графика, чтобы использовать её в легенде\n",
    "    line1, = ax2.plot(range(1, len(output['times'])+1), output['times'], 'ro-', label='Время работы')\n",
    "    \n",
    "    # Добавляем горизонтальную линию на уровне y, также с меткой\n",
    "    line2 = ax1.axhline(y=y, color='g', linestyle='--', label='Желаемая ошибка')\n",
    "    \n",
    "    # Устанавливаем подписи для осей\n",
    "    ax1.set_ylabel('Ошибки, %', color='b')\n",
    "    ax2.set_ylabel('Время, сек', color='r')\n",
    "    \n",
    "    # Устанавливаем цвета для осей\n",
    "    for tl in ax1.get_yticklabels():\n",
    "        tl.set_color('b')\n",
    "    for tl in ax2.get_yticklabels():\n",
    "        tl.set_color('r')\n",
    "    \n",
    "    ax1.set_xlabel('k, отношение кластеров к узлам графа')\n",
    "    plt.title('Поиск оптимального отношения кластеров к кол-ву узлов в графе')\n",
    "    \n",
    "    # Добавляем легенду\n",
    "    lines = [line1, line2]\n",
    "    ax1.legend(lines, [l.get_label() for l in lines])\n",
    "    \n",
    "    # Создание папки, если она не существует\n",
    "    directory = \"data/img\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Запись PNG\n",
    "    file_path = os.path.join(directory, f\"boxplot_{H.graph['id']}.png\")\n",
    "    plt.savefig(file_path, dpi=120)\n",
    "    \n",
    "    print(f\"График boxplot был сохранён в {file_path}\")\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cities_with_population_greater_than_n(n):\n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "    overpass_query = \"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "            relation[\"place\"=\"city\"];\n",
    "            relation[\"place\"=\"town\"];\n",
    "            relation[\"place\"=\"village\"];\n",
    "        );\n",
    "        out;\n",
    "    \"\"\"\n",
    "    response = requests.get(overpass_url, params={\"data\": overpass_query})\n",
    "    data = response.json()\n",
    "\n",
    "    result = {\n",
    "        'cities': [],\n",
    "        'city_ids': [],\n",
    "        'population_list': [],\n",
    "        'place': []\n",
    "    }\n",
    "\n",
    "    for element in tqdm(data[\"elements\"], leave=False):\n",
    "        if \"population\" in element[\"tags\"]:\n",
    "            population = element[\"tags\"][\"population\"].replace(\" \", \"\")\n",
    "            try:\n",
    "                population = int(population)\n",
    "                if population >= n:\n",
    "                    if \"name\" in element[\"tags\"]:\n",
    "                        result['cities'].append(element['tags']['name'])  # Добавляем название города в список городов\n",
    "                        result['city_ids'].append(element['id'])  # Добавляем идентификатор в список идентификаторов\n",
    "                        result['population_list'].append(element[\"tags\"][\"population\"].replace(\" \", \"\"))\n",
    "                        result['place'].append(element['tags']['place'])\n",
    "            except ValueError:\n",
    "                # Здесь можно добавить логирование или другую обработку ошибок\n",
    "                print(f\"Не удалось преобразовать население в число для {element['tags'].get('name', 'неизвестного города')}\")\n",
    "    \n",
    "    return pd.DataFrame(result)  # Возвращаем оба списка    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    min_population = 30000  # Задайте минимальное население\n",
    "    result = get_cities_with_population_greater_than_n(min_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = list(result['city_ids'].apply(lambda x: 'R'+str(x)))                      # Тут все id для теста\n",
    "ids = ['R13470549']\n",
    "resolutions = [\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    5,\n",
    "    6,\n",
    "    8,\n",
    "    10,\n",
    "    14,\n",
    "    18,\n",
    "    22,\n",
    "    26,\n",
    "    32,\n",
    "    36,\n",
    "    40,\n",
    "    46,\n",
    "    50,\n",
    "    55,\n",
    "    65,\n",
    "    75,\n",
    "    85,\n",
    "    95,\n",
    "    110\n",
    "]\n",
    "for id in ids[:1]:\n",
    "    try:\n",
    "        H = download_graph(id, simplify=True)                                   # Загрузка графа\n",
    "        # resolutions, ks, v1, e1 = search_resolutions(H, k_max=0.6)              # Находим набор рабочих resolutions, ks, (v1, e1) для каждого графа\n",
    "        # visualisation(H, v1, e1)                                                # Визуализация времени работы по ks и формуле\n",
    "        output, mistakes = test(H, resolutions, k=10000, weight='length')           # Тест графа\n",
    "        box_visualisation(H, output, mistakes)                                  # Визуализация ошибки boxplot`ом\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка при обработке графа с id {id}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing graphs:  52%|█████▏    | 396/756 [1:23:35<1:15:59, 12.67s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m number \u001b[38;5;129;01min\u001b[39;00m tqdm(numbers, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 70\u001b[0m     \u001b[43mprocess_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodularity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: get_modularity(row, return_dict), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Сохранение DataFrame в CSV файл\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 36\u001b[0m, in \u001b[0;36mprocess_graph\u001b[1;34m(number, return_dict)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile for R\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m resolutions \u001b[38;5;241m=\u001b[39m \u001b[43msearch_resolutions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m resolution \u001b[38;5;129;01min\u001b[39;00m resolutions:\n\u001b[0;32m     39\u001b[0m     communities \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mcommunity\u001b[38;5;241m.\u001b[39mlouvain_communities(H, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m, resolution\u001b[38;5;241m=\u001b[39mresolution)\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36msearch_resolutions\u001b[1;34m(H, resolution, weight, k_max)\u001b[0m\n\u001b[0;32m     13\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m k \u001b[38;5;241m<\u001b[39m k_max:\n\u001b[1;32m---> 16\u001b[0m     H, communities \u001b[38;5;241m=\u001b[39m \u001b[43mlouvain_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(communities) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(H\u001b[38;5;241m.\u001b[39mnodes)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.008\u001b[39m:\n",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m, in \u001b[0;36mlouvain_clusters\u001b[1;34m(H, seed, weight, resolution)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlouvain_clusters\u001b[39m(H, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m, resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     communities \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlouvain_communities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m H, communities\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 13:4\u001b[0m, in \u001b[0;36margmap_louvain_communities_10\u001b[1;34m(G, weight, resolution, threshold, seed, backend, **backend_kwargs)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[1;32md:\\IT\\GitHub\\graph-topology-in-routing-problems\\.venv\\lib\\site-packages\\networkx\\utils\\backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[1;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[1;32md:\\IT\\GitHub\\graph-topology-in-routing-problems\\.venv\\lib\\site-packages\\networkx\\algorithms\\community\\louvain.py:119\u001b[0m, in \u001b[0;36mlouvain_communities\u001b[1;34m(G, weight, resolution, threshold, seed)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Find the best partition of a graph using the Louvain Community Detection\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mAlgorithm.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03mlouvain_partitions\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m d \u001b[38;5;241m=\u001b[39m louvain_partitions(G, weight, resolution, threshold, seed)\n\u001b[1;32m--> 119\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[43mdeque\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[1;32md:\\IT\\GitHub\\graph-topology-in-routing-problems\\.venv\\lib\\site-packages\\networkx\\algorithms\\community\\louvain.py:211\u001b[0m, in \u001b[0;36mlouvain_partitions\u001b[1;34m(G, weight, resolution, threshold, seed)\u001b[0m\n\u001b[0;32m    209\u001b[0m mod \u001b[38;5;241m=\u001b[39m new_mod\n\u001b[0;32m    210\u001b[0m graph \u001b[38;5;241m=\u001b[39m _gen_graph(graph, inner_partition)\n\u001b[1;32m--> 211\u001b[0m partition, inner_partition, improvement \u001b[38;5;241m=\u001b[39m \u001b[43m_one_level\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_directed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\IT\\GitHub\\graph-topology-in-routing-problems\\.venv\\lib\\site-packages\\networkx\\algorithms\\community\\louvain.py:266\u001b[0m, in \u001b[0;36m_one_level\u001b[1;34m(G, m, partition, resolution, is_directed, seed)\u001b[0m\n\u001b[0;32m    264\u001b[0m best_mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    265\u001b[0m best_com \u001b[38;5;241m=\u001b[39m node2com[u]\n\u001b[1;32m--> 266\u001b[0m weights2com \u001b[38;5;241m=\u001b[39m \u001b[43m_neighbor_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode2com\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_directed:\n\u001b[0;32m    268\u001b[0m     in_degree \u001b[38;5;241m=\u001b[39m in_degrees[u]\n",
      "File \u001b[1;32md:\\IT\\GitHub\\graph-topology-in-routing-problems\\.venv\\lib\\site-packages\\networkx\\algorithms\\community\\louvain.py:337\u001b[0m, in \u001b[0;36m_neighbor_weights\u001b[1;34m(nbrs, node2com)\u001b[0m\n\u001b[0;32m    335\u001b[0m weights \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nbr, wt \u001b[38;5;129;01min\u001b[39;00m nbrs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 337\u001b[0m     weights[node2com[nbr]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m wt\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "def louvain_clusters(H, seed=42, weight='length', resolution=1):\n",
    "    communities = nx.community.louvain_communities(H, seed=seed, weight=weight, resolution=resolution)\n",
    "    return H, communities\n",
    "\n",
    "# Функция для поиска разрешений\n",
    "def search_resolutions(H, resolution=0.001, weight='length', k_max=0.7):\n",
    "    resolutions = []\n",
    "    k = 0\n",
    "\n",
    "    while k < k_max:\n",
    "        H, communities = louvain_clusters(H, resolution=resolution, weight=weight)\n",
    "        k = len(communities) / len(H.nodes)\n",
    "        if k < 0.008:\n",
    "            resolution *= 3\n",
    "            continue\n",
    "        else:\n",
    "            resolutions.append(resolution)\n",
    "            resolution *= 3\n",
    "\n",
    "    return resolutions\n",
    "\n",
    "# Функция обработки графа\n",
    "def process_graph(number, return_dict):\n",
    "    # print(f\"Processing graph {number}\")\n",
    "    try:\n",
    "        H = nx.read_graphml(f'data/graphs_1/graph_R{number}.graphml')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for R{number} not found.\")\n",
    "        return\n",
    "\n",
    "    resolutions = search_resolutions(H, k_max=0.7)\n",
    "\n",
    "    for resolution in resolutions:\n",
    "        communities = nx.community.louvain_communities(H, seed=42, weight='length', resolution=resolution)\n",
    "        alpha = len(communities) / len(H.nodes)\n",
    "        modularity = nx.community.modularity(H, communities)\n",
    "\n",
    "        if number not in return_dict:\n",
    "            return_dict[number] = {}\n",
    "        return_dict[number][round(alpha, 3)] = modularity\n",
    "\n",
    "# Функция для поиска ближайшего значения\n",
    "def find_closest_value(alpha, alpha_dict):\n",
    "    return min(alpha_dict.keys(), key=lambda x: abs(x - alpha))\n",
    "\n",
    "# Функция для получения модулярности\n",
    "def get_modularity(row, diction):\n",
    "    r_number = row['R_number']\n",
    "    alpha = round(row['alpha'], 3)\n",
    "    if r_number in diction:\n",
    "        closest_alpha = find_closest_value(alpha, diction[r_number])\n",
    "        return diction[r_number][closest_alpha]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Загрузка данных\n",
    "    df = pd.read_csv('more_info_for_cities_3.csv')\n",
    "    result = df.loc[df.groupby('R_number')['speed_up'].idxmax()]\n",
    "    numbers = list(result['R_number'].values)\n",
    "\n",
    "    return_dict = {}\n",
    "\n",
    "    for number in tqdm(numbers, desc=\"Processing graphs\"):\n",
    "        process_graph(number, return_dict)\n",
    "\n",
    "    df['modularity'] = df.apply(lambda row: get_modularity(row, return_dict), axis=1)\n",
    "\n",
    "    # Сохранение DataFrame в CSV файл\n",
    "    df.to_csv('output_dataframe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SBER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
